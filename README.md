
# 信用卡交易欺诈检测

***

团队简介
- 团队名称：Tech Ferris Wheel
- 团队成员：ZMark 

问题陈述
- 信用卡交易欺诈是一个严重的问题，对银行、客户和商户造成了巨大的经济损失。机器学习在欺诈检测方面显示出巨大的潜力，因为它可以通过分析大量数据并发现模式来快速、准确地检测欺诈行为。

技术栈和实现方案
- python3.7
  - numpy
  - pandas
  - matplotlib
  - sklearn
  - modin
  - xgboost
  - lightgbm
  - torch
- 英特尔®oneAPI AI分析工具包
  - modin
  - sklearnex

团队学到了什么
- 各种分类算法
- 英特尔®oneAPI AI分析工具包的使用

***

> 代码——`credit_card_fraud_detection.ipynb`
> 报告——如下

## 一、项目简介

针对信用卡交易欺诈检测数据集，我们通过不同的数据预处理、选择不同的模型、进行不同的超参数调优，对多个训练方案进行和评估，经过实验和数据对比，寻找合适的数据预处理方法、合适的模型和训练方法。

同时，也使用英特尔®oneAPI AI分析工具包进行训练，对比其带来的性能提升。

## 二、数据集

来自<https://filerepo.idzcn.com/dataset/assignment_1.zip>的`creditcard.csv

## 三、数据概览与分析

在开始建模之前，进行数据概览与分析，即notebook中的`三、数据探索与预处理`部分。

### 1.特征概览

- Time：所有交易与第一个交易的时间间隔（单位秒）
- V1-V28
	- 是PCA后的特征，因为需要保密，所以不知道原始信息，不清楚数据的具体含义
	- 已经经过了降维处理，因此我们不需要对数据再进行预处理
- Amount：交易金额
- Class即为分类标签，1代表存在欺诈行为，0代表正常交易

### 2.空值概览

没有空值，不需要处理缺失

### 3.分类标签（欺诈交易）的分布

通过柱状图来查看分类标签的分布

![[output_24_1.png]](imgs/output_24_1.png)

可以看到，欺诈交易数量较少(Class=1)，样本分布不均匀，需要进行处理

### 4.分类标签相对于交易时间（Time）的分布

```
Normal (Class=0): 
count    284315.000000
mean      94838.202258
std       47484.015786
min           0.000000
25%       54230.000000
50%       84711.000000
75%      139333.000000
max      172792.000000
Name: Time, dtype: float64
```

```
Fraud (Class=1): 
count       492.000000
mean      80746.806911
std       47835.365138
min         406.000000
25%       41241.500000
50%       75568.500000
75%      128483.000000
max      170348.000000
Name: Time, dtype: float64
```

![[output_27_1.png]](imgs/output_27_1.png)

从Time的description和分布图来看：

- 欺诈交易分布更加均匀
- 正常交易似乎有交易周期
- 在正常交易的交易低频时间段更容易检测到欺诈交易

### 5.分类标签相对于交易金额（Amount）的分布

```
Normal
count    284315.000000
mean         88.291022
std         250.105092
min           0.000000
25%           5.650000
50%          22.000000
75%          77.050000
max       25691.160000
Name: Amount, dtype: float64
```

```
Fraud
count     492.000000
mean      122.211321
std       256.683288
min         0.000000
25%         1.000000
50%         9.250000
75%       105.890000
max      2125.870000
Name: Amount, dtype: float64
```

![[output_30_1.png]](imgs/output_30_1.png)

从Amount的description和分布图来看：

- 在金额上，欺诈交易和正常交易的分布差距较大
- 欺诈交易的金额较小，最大值只有2125.87，而且集中在小金额交易中
- Amount的标准差较大，需要归一化处理

可能的数据预处理：

1. Time可能与是否欺诈乜有逻辑上的关系，可能需要去除
2. Amount的标准差较大，需要归一化处理
3. 处理样本不均匀的问题

## 四、模型与训练方案

### 1.二分类问题——模型选择

针对信用卡交易欺诈检测问题，这样一个二分类问题，使用了以下模型：

- 逻辑回归 (Logistic Regression)
	- 逻辑回归是二分类问题的经典算法，易于实现和解释。它对于大规模数据集也具有较好的性能
- 决策树 (Decision Trees)
	- 决策树是一种直观且易于解释的模型，对于处理非线性关系和异常值具有一定的鲁棒性
- 随机森林 (Random Forest)
	- 随机森林是一种集成学习方法，通过组合多个决策树来提高性能，并对过拟合具有一定的抵抗力
- 支持向量机 (Support Vector Machines - SVM)
	- SVM 在处理高维数据和处理不平衡数据方面表现良好。可以通过调整参数来适应不同的数据分布
- 神经网络 (Neural Networks)
	- 深度学习模型，特别是神经网络，在处理复杂的非线性关系方面可能表现得很好。可以通过调整网络结构和训练策略来适应数据
- 梯度提升树 (Gradient Boosting Trees)
	- 梯度提升树通过迭代训练多个弱分类器，逐步提升模型性能
	- 选择了两个模型
		- XGBoost
		- LightGBM

### 2.分布不平衡——下采样与过采样技术

为了解决类别不平衡问题，采用了下采样和过采样技术来平衡样本分布。

### 3.模型超参数调整——折交叉验证技术和网格搜索技术

为了调整模型超参数，采用了k折交叉验证技术和网格搜索技术。

### 4.方案设计

具体代码见notebook中的`五、定义数据预处理函数`和`六、定义模型训练函数

设计了三种预处理方案：
![[Pasted image 20231115135104.png]](imgs/Pasted%20image%2020231115135104.png)

设计了十二种方案
![[Pasted image 20231115135128.png|300]](imgs/Pasted%20image%2020231115135128.png)

## 五、模型训练与评估

将数据拆分为训练集和测试集，使用训练集训练模型，并使用测试集评估其性能。

### 评估指标

选择的评估指标包括：

- 二分类准确度（F1分数
- 精确率-召回率曲线下面积 (AUPRC)
- 推理时间
- 训练时间

### 测试结果

得到数据如下：

| 方案              | f1        | auprc     | train_time | inference_time |
| --------------- | --------- | --------- | ---------- | -------------- |
| 基础逻辑回归模型        | 0.695122  | 0.75977   | 0.529599   | 0.0117321      |
| 下采样+逻辑回归模型      | 0.957895  | 0.995065  | 0.00399971 | 0.000999689    |
| 过采样+逻辑回归模型      | 0.109823  | 0.770562  | 2.10447    | 0.0117676      |
| 基础逻辑回归模型+k折验证   | 0.687117  | 0.716852  | 12.8932    | 0.605599       |
| 下采样+逻辑回归模型+k折验证 | 0.963731  | 0.979606  | 0.170085   | 0.00769281     |
| 过采样+逻辑回归模型+k折验证 | 0.109622  | 0.488399  | 42.8736    | 2.21025        |
| 基础随机森林模型        | 0.857143  | 0.869868  | 231.25     | 0.339336       |
| 下采样+随机森林模型      | 0.957895  | 0.979901  | 0.282911   | 0.0070076      |
| 过采样+随机森林模型      | 0.875     | 0.875503  | 392.804    | 0.366926       |
| 基础SVM模型         | 0.802083  | 0.643986  | 0          | 597.781        |
| 下采样+SVM模型       | 0.941176  | 0.944726  | 0          | 0.00599694     |
| 过采样+SVM模型       | 0.112923  | 0.0553898 | 0          | 6336.11        |
| 基础XGBoost模型     | 0.882682  | 0.786552  | 7.36704    | 0.0203736      |
| 下采样+XGBoost模型   | 0.958333  | 0.954834  | 0.0479305  | 0.00250888     |
| 过采样+XGBoost模型   | 0.813397  | 0.664413  | 21.1855    | 0.0207493      |
| 基础LightGBM模型    | 0.288066  | 0.0873129 | 0.419755   | 0.0236313      |
| 下采样+LightGBM模型  | 0.957895  | 0.959801  | 0.0508235  | 0.00200391     |
| 过采样+LightGBM模型  | 0.677165  | 0.483989  | 0.834558   | 0.0292869      |
| 基础神经网络模型        | 0.788571  | 0.845934  | 43.1648    | 0.0208828      |
| 下采样+神经网络模型      | 0.958333  | 0.992847  | 0.147449   | 0.00250602     |
| 过采样+神经网络模型      | 0.674419  | 0.72335   | 88.9837    | 0.0169113      |
| 基础决策树模型         | 0.737864  | 0.7398    | 16.9895    | 0.00869775     |
| 下采样+决策树模型       | 0.903553  | 0.928957  | 0.0197394  | 0.000505924    |
| 过采样+决策树模型       | 0.535714  | 0.588899  | 38.7989    | 0.0096674      |
| 基础决策树模型+网格搜索    | 0.84153   | 0.845983  | 555.203    | 0.022311       |
| 下采样+决策树模型+网格搜索  | 0.93617   | 0.966745  | 1.3302     | 0.022311       |
| 过采样+决策树模型+网格搜索  | 0.0903226 | 0.452531  | 1104.46    | 0.022311       |
| 逻辑回归模型+网格搜索     | 0.695122  | 0.759534  | 8.04417    | 0.00304842     |
| 下采样+逻辑回归模型+网格搜索 | 0.963731  | 0.995185  | 0.0983825  | 0              |
| 过采样+逻辑回归模型+网格搜索 | 0.109489  | 0.770525  | 27.4987    | 0.00300026     |
| 基础决策树模型+k折验证    | 0.84153   | 0.845983  | 234.922    | 4.85233        |
| 下采样+决策树模型+k折验证  | 0.925532  | 0.958615  | 0.379019   | 0.012511       |
| 过采样+决策树模型+k折验证  | 0.535714  | 0.588899  | 450.22     | 34.4485        |

> [!info] 预处理说明
>
> - 均对Amount进行归一化处理
> - 均去除Time特征

> [!info] 测试环境说明
> 可能是同时段使用Intel云服务器的人数过多，Intel云服务器上的notebook无法正常测试，这部分数据使用自己的电脑进行测试

## 六、多训练方案结果分析

对上一步得到的数据进行绘图，以进行可视化分析，代码见notebook中的`八、结果比较与分析`

### 1.模型性能

![[Pasted image 20231115153059.png]](imgs/Pasted%20image%2020231115153059.png)

<center>图1：不同方案下AUPRC值比较的柱状图</center>

![[Pasted image 20231115153520.png]](imgs/Pasted%20image%2020231115153520.png)

<center>图2：不同方案下F1值比较的柱状图</center>

通过图1和图2，可以发现

- 下采样+逻辑回归模型在大多数情况下表现良好，具有较高的f1和auprc值。而过采样+逻辑回归模型通常表现较差。
- 其中**准确度（F1）最优方案**为：
	- 下采样+逻辑回归模型+k折验证，F1为0.963731。

### 2.训练时间和推理时间

![[Pasted image 20231115153612.png]](imgs/Pasted%20image%2020231115153612.png)

<center>图3：不同方案下训练时间、推理时间比较的柱折图</center>

![[Pasted image 20231115153719.png]](imgs/Pasted%20image%2020231115153719.png)

<center>图4：不同方案下训练时间、推理时间比较的柱折图（详细）</center>

通过图3和图4可以分发现

- 基础逻辑回归和下采样+逻辑回归模型通常具有较短的训练和推断时间。
- 其中
	- **训练时间最优方案：**
		- 下采样+逻辑回归模型，训练时间为0.00399971。
	- **推理时间最优方案：**
		- 下采样+逻辑回归模型，推理时间为0.000999689。

### 3.采样技术的影响

在逻辑回归、随机森林、XGBoost、LightGBM和神经网络等模型中，下采样技术似乎在大多数情况下提高了性能，而过采样则通常导致性能下降。

对于下采样和过采样的优劣分析如下：

#### 下采样 (Undersampling)

**优势:**

1. **计算效率高：** 由于减少了多数类样本的数量，训练过程更加迅速，模型的计算效率更高。
2. **降低过拟合风险：** 减少多数类样本有助于减轻模型对多数类的过度学习，从而降低过拟合的风险。

**劣势:**

1. **信息损失：** 下采样可能会导致信息损失，因为舍弃了多数类的大部分样本，模型可能对多数类的特征学习不足。
2. **不适用于小数据集：** 如果原始数据集本身就很小，进行下采样可能导致样本数量过少，难以保持模型的泛化能力。

#### 过采样 (Oversampling):

**优势:**

1. **更充分地利用信息：** 过采样通过复制或生成少数类样本，使得模型更充分地利用了所有类别的信息，有助于提高模型对少数类的识别能力。
2. **适用于小数据集：** 过采样可以在数据集较小的情况下增加训练样本的数量，有助于改善模型的性能。

**劣势:**

1. **可能引入噪声：** 复制或生成样本可能引入一定程度的噪声，特别是如果样本之间存在相关性，可能导致模型对噪声过度拟合。
2. **计算成本增加：** 增加了样本数量会导致计算成本的增加，训练时间可能变得较长

### 4.网格搜索的效果

- 使用网格搜索进行超参数调整时，有些模型在性能上取得了改善，而有些模型却没有。
- 例如，基础决策树模型和下采样+决策树模型在网格搜索后性能提高，而过采样+决策树模型的性能改善有限。

这些结果表明，在给定数据集和问题背景下，下采样+逻辑回归模型在多个方面表现优异，具有较高的准确度（F1），较短的训练时间和推理时间

## 七、英特尔®oneAPI AI分析工具包性能分析

选取训练时间和推理时间较长的方案，如下：

- 训练时间较长的方案：过采样+随机森林模型，官方机器学习库，训练时间392.804
- 推理时间较长的方案：基础SVM模型，官方机器学习库，推理时间597.781

实验一：使用官方机器学习库进行训练和推理。

实验二：使用英特尔®oneAPI AI分析工具包进行训练和推理。

比较实验一与实验二是否有性能上的优化

### 1.开启方式

首先，在notebook的`二、导入模块（使用oneAPI）`中如下设置（注释官方模块导入，打开英特尔®oneAPI模块导入）：

```python
import os
import numpy as np
import warnings

# 导入相关的python模块，忽略 warnings 信息
warnings.filterwarnings("ignore")

## 使用原生pandas
# import pandas as pd

# 使用modin
# 导入 Modin 库，设置 HDK (Heterogeneous Data Kernels) 作为后端计算引擎，该引擎基于OmniSciDB来获得针对特定dataframe操作集的高单节点可扩展性
import modin.pandas as pd
import modin.config as cfg
cfg.StorageFormat.put('hdk')

# 导入Intel® Extension for Scikit-learn库，调用patch函数，从而在运行时调用底层 Intel® oneAPI Data Analytics Library 对机器学习算法进行加速
# 以下两行导入Intel® Extension for Scikit-learn库，调用patch函数加速。如果使用原生的scikit-learn, 注释这两行即可
from sklearnex import patch_sklearn
patch_sklearn()

print("导入模块成功")
```

其次重新运行notebook中的`三、加载数据`、`五、定义数据预处理函数`中全部单元格

再运行notebook中的`六、定义模型训练函数`中某个具体方案的单元格

然后运行`七、训练与测试`中`定义测试保存函数`的单元格，

最后运行`七、训练与测试`中某个具体方案的单元格

### 2.效果对比

如下图，由于intel的云服务器中kernel会奔溃，然后Restart，无法按照预定计划进行详细的测试，只能选择小模型进行测试对比。
![[Pasted image 20231115145526.png]](imgs/Pasted%20image%2020231115145526.png)

针对基础逻辑回归模型，得到如下数据：

| 实验                                  | Train time（秒）      | Inference time（秒）    |
| ----------------------------------- | ------------------ | -------------------- |
| 实验一：（Intel云服务器）官方机器学习库              | 0.8968212604522705 | 0.027785301208496094 |
| 实验二：（Intel云服务器）使用英特尔®oneAPI AI分析工具包 | 0.5063996315002441 | 0.14398789405822754  |

可以看到，使用英特尔®oneAPI AI分析工具包进行训练，可以减少43%的训练时间，效果显著。

#### 部分结果截图

使用官方机器学习库：
![[Pasted image 20231115150523.png|300]](imgs/Pasted%20image%2020231115150523.png)

使用英特尔®oneAPI AI分析工具包：
![[Pasted image 20231115145227.png|400]](imgs/Pasted%20image%2020231115145227.png)

## 八、改进和未来工作

### 1.改进模型训练过程

我们可以通过以下方式改进模型：

- 更精细的数据预处理，例如分析所有的特征分布，去除一些无关特征
- 超参数调整：通过更详细的超参数搜索来优化模型性能。
- 集成学习：尝试使用集成学习方法，如投票分类器，进一步提高模型的鲁棒性。

### 2.进一步对比英特尔®oneAPI AI分析工具包带来的性能提升

在这一部分，实验数量不够多，也没有能够完成既定方案的对比，可以在服务器资源空闲时，利用英特尔®oneAPI AI分析工具包，测试更多的方案。

## 九、结论

针对信用卡交易欺诈检测数据集，我们通过不同的数据预处理、选择不同的模型、进行不同的超参数调优，对多个训练方案进行和评估，经过实验和数据对比，我们发现：

- **准确度（F1）最优方案**为：下采样+逻辑回归模型+k折验证，F1为0.963731。
- **训练时间最优方案**为：下采样+逻辑回归模型，训练时间为0.00399971。
- **推理时间最优方案**为：下采样+逻辑回归模型，推理时间为0.000999689。
- 综合推荐方案：**下采样+逻辑回归模型+k折交叉验证**

另外，通过实验对比，使用英特尔®oneAPI AI分析工具包进行训练，可以减少43%的训练时间，效果显著。
